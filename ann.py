# -*- coding: utf-8 -*-
"""ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nJMLAGN2goilMTPw78-mlxU6o5jux3F5
"""

from google.colab import files #Upload Files Google Colab
dataset = files.upload()

#Libraries Section
import numpy as np 
import matplotlib.pyplot as plt
import pandas as pd
import io
import keras
np.set_printoptions(threshold=np.nan)
import sys

print (dataset['Churn_Modelling.csv'][:200].decode('utf-8') + '...')
dataset = pd.read_csv(io.StringIO(dataset['Churn_Modelling.csv'].decode('utf-8')))

# Preparing X and y 
X = dataset.iloc[:,3:13].values
y = dataset.iloc[:,-1:].values

# Encoding Categories
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

labelencoder_X_1 = LabelEncoder()
X[:,1] = labelencoder_X_1.fit_transform(X[:,1])

labelencoder_X_2 = LabelEncoder()
X[:,2] = labelencoder_X_2.fit_transform(X[:,2])

onehotencoder = OneHotEncoder(categorical_features = [1])
X = onehotencoder.fit_transform(X).toarray()

#remove dummy variable 
X = X[:,1:]

#Split
from sklearn.model_selection import train_test_split 
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)

#Feature Scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test =scaler.transform(X_test)

#Importing Keras packages
from keras.models import Sequential ## initialize neural network
from keras.layers import Dense ## create the layers of the neural network

# Initializing ANN(defining sequence of layers or defining a graph)
classifier = Sequential()
classifier.add(Dense(6, input_shape=(11,), activation ='relu',kernel_initializer='uniform'))
classifier.add(Dense(6, activation ='relu',kernel_initializer='uniform'))
classifier.add(Dense(1, activation ='sigmoid',kernel_initializer='uniform')) ##softmax if more than one dependant variables

# Compiling the ANN by applying gradient descent
classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

#Fit ANN to the training Set
classifier.fit(X_train,y_train,batch_size=10,nb_epoch=100)

#predicting
y_pred = classifier.predict(X_test)
y_pred = (y_pred>0.5)

#Confusion Matrix
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,y_pred)
print(cm)

#Evaluating ANN
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score

def build_classifier():
  classifier = Sequential()
  classifier.add(Dense(6, input_shape=(11,), activation ='relu',kernel_initializer='uniform'))
  classifier.add(Dense(6, activation ='relu',kernel_initializer='uniform'))
  classifier.add(Dense(1, activation ='sigmoid',kernel_initializer='uniform'))
  classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
  return classifier
classifier = KerasClassifier(build_fn=build_classifier,batch_size=10,epochs=100)

accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train,cv=10, n_jobs=-1)
mean = accuracies.mean()
variance = accuracies.std()

#Drop OUT Regularization
from keras.layers import Dropout
def build_classifier():
  classifier = Sequential()
  classifier.add(Dense(6, input_shape=(11,), activation ='relu',kernel_initializer='uniform'))
  classifier.add(Dropout(p=0.1)) # increase P until resolving overfitting no more than 0.5 cause of underfitting
  classifier.add(Dense(6, activation ='relu',kernel_initializer='uniform'))
  classifier.add(Dense(1, activation ='sigmoid',kernel_initializer='uniform'))
  classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
  return classifier
classifier.fit(X_train,y_train,batch_size=10,epochs=100)

#Tuning ANN
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import GridSearchCV

def build_classifier(optimizer):
  classifier = Sequential()
  classifier.add(Dense(6, input_shape=(11,), activation ='relu',kernel_initializer='uniform'))
  classifier.add(Dense(6, activation ='relu',kernel_initializer='uniform'))
  classifier.add(Dense(1, activation ='sigmoid',kernel_initializer='uniform'))
  classifier.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])
  return classifier

classifier = KerasClassifier(build_fn=build_classifier)

parameters = {'batch_size':[25, 32],
              'epochs':[50, 100, 200, 300],
              'optimizer':['adam','rmsprop']} ##rmsprop recommended for RNN
grid_search = GridSearchCV(estimator = classifier,
                           param_grid=parameters,
                           scoring = 'accuracy',
                           cv=10)

grid_search = grid_search.fit(X_train,y_train)
best_parameters= grid_search.best_params_
best_accuracy=grid_search.best_score_



